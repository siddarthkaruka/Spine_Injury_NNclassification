{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nearest neighbor for spine injury classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we use **nearest neighbor classification** to classify back injuries for patients in a hospital, based on measurements of the shape and orientation of their pelvis and spine.\n",
    "\n",
    "The data set contains information from **310** patients. For each patient, there are: six measurements (the x) and a label (the y). The label has **3** possible values, `’NO’` (normal), `’DH’` (herniated disk), or `’SL’` (spondilolysthesis). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Setup notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import all necessary packages for the homework. Notice that we do **NOT** import any of the `sklearn` packages. This is because we want to implement a nearest neighbor classifier **manually**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now load the dataset. We divide the data into a training set of 248 patients and a separate test set of 62 patients. The following arrays are created:\n",
    "\n",
    "* **`trainx`** : The training data's features, one point per row.\n",
    "* **`trainy`** : The training data's labels.\n",
    "* **`testx`** : The test data's features, one point per row.\n",
    "* **`testy`** : The test data's labels.\n",
    "\n",
    "We will use the training set (`trainx` and `trainy`), with nearest neighbor classification, to predict labels for the test data (`testx`). We will then compare these predictions with the correct labels, `testy`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that we code the three labels as `0. = ’NO’, 1. = ’DH’, 2. = ’SL’`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data set and code labels as 0 = ’NO’, 1 = ’DH’, 2 = ’SL’\n",
    "labels = [b'NO', b'DH', b'SL']\n",
    "data = np.loadtxt('column_3C.dat', converters={6: lambda s: labels.index(s)} )\n",
    "\n",
    "# Separate features from labels\n",
    "x = data[:,0:6]\n",
    "y = data[:,6]\n",
    "\n",
    "# Divide into training and test set\n",
    "training_indices = list(range(0,20)) + list(range(40,188)) + list(range(230,310))\n",
    "test_indices = list(range(20,40)) + list(range(188,230))\n",
    "\n",
    "trainx = x[training_indices,:]\n",
    "trainy = y[training_indices]\n",
    "testx = x[test_indices,:]\n",
    "testy = y[test_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Nearest neighbor classification with L2 distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will build a nearest neighbor classifier based on L2 (*Euclidean*) distance.\n",
    "\n",
    "The function, **NN_L2**, takes as input the training data (`trainx` and `trainy`) and the test points (`testx`) and predicts labels for these test points using 1-NN classification. These labels are returned in a `numpy` array with one entry per test point. For **NN_L2**, the L2 norm is used as the distance metric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<font  style=\"color:blue\"> **Code**</font>\n",
    "```python\n",
    "# test function \n",
    "testy_L2 = NN_L2(trainx, trainy, testx)\n",
    "print( type( testy_L2) )\n",
    "print( len(testy_L2) )\n",
    "print( testy_L2[40:50] )\n",
    "```\n",
    "\n",
    "<font  style=\"color:magenta\"> **Output**</font>\n",
    "```\n",
    "<class 'numpy.ndarray'>\n",
    "62\n",
    "[ 2.  2.  1.  0.  0.  0.  0.  0.  0.  0.]\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify this Cell\n",
    "\n",
    "def NN_L2(trainx, trainy, testx):\n",
    "    # inputs: trainx, trainy, testx <-- as defined above\n",
    "    # output: an np.array of the predicted values for testy \n",
    "    distances = np.array([[np.sum(np.square(testx[i,]-trainx[j,])) for j in range(len(trainx))]\n",
    "                          for i in range(len(testx))])\n",
    "    \n",
    "    return trainy[np.argmin(a,axis=1)]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([170, 187, 182,  19,  28, 187,  11, 209, 235,  16, 229,  35, 235,\n",
       "       196,  14,   1,  17, 228,  14,  30, 116, 126, 105, 108,  56,  77,\n",
       "        43,  77,  86,  94,  81,  46,  89,  94,  94,  82, 152,  41, 102,\n",
       "       145, 101, 110,  18, 221, 233, 221, 232, 234, 238, 172, 214, 182,\n",
       "       235, 208, 133, 192, 151, 175, 175, 224, 212, 171])"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=np.array([[np.sum(np.square(testx[i,]-trainx[j,])) for j in range(len(trainx))] for i in range(len(testx))])\n",
    "np.argmin(a,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testy_L2 = NN_L2(trainx, trainy, testx)\n",
    "len(testy_L2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "testy_L2 = NN_L2(trainx, trainy, testx)\n",
    "\n",
    "assert( type( testy_L2).__name__ == 'ndarray' )\n",
    "assert( len(testy_L2) == 62 ) \n",
    "assert( np.all( testy_L2[50:60] == [ 0.,  0.,  0.,  0.,  2.,  0.,  2.,  0.,  0.,  0.] )  )\n",
    "assert( np.all( testy_L2[0:10] == [ 0.,  0.,  0.,  1.,  1.,  0.,  1.,  0.,  0.,  1.] ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Nearest neighbor classification with L1 distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now compute nearest neighbors using the L1 distance (sometimes called *Manhattan Distance*).\n",
    "\n",
    "The function, **NN_L1**, takes as input the arrays `trainx`, `trainy`, and `testx`, and predicts labels for the test points using 1-nearest neighbor classification. For **NN_L1**, the L1 distance metric should be used. As before, the predicted labels are returned in a `numpy` array with one entry per test point.\n",
    "\n",
    "Notice that **NN_L1** and **NN_L2** may well produce different predictions on the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<font  style=\"color:blue\"> **Code**</font>\n",
    "```python\n",
    "# test function \n",
    "testy_L2 = NN_L2(trainx, trainy, testx)\n",
    "testy_L1 = NN_L1(trainx, trainy, testx)\n",
    "\n",
    "print( type( testy_L1) )\n",
    "print( len(testy_L1) )\n",
    "print( testy_L1[40:50] )\n",
    "print( all(testy_L1 == testy_L2) )\n",
    "```\n",
    "\n",
    "<font  style=\"color:magenta\"> **Output**</font>\n",
    "```\n",
    "<class 'numpy.ndarray'>\n",
    "62\n",
    "[ 2.  2.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
    "False\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify this Cell\n",
    "\n",
    "def NN_L1(trainx, trainy, testx):\n",
    "    # inputs: trainx, trainy, testx <-- as defined above\n",
    "    # output: an np.array of the predicted values for testy \n",
    "    distances = np.array([[np.sum(np.absolute(testx[i,]-trainx[j,])) for j in range(len(trainx))] \n",
    "                          for i in range(len(testx))])\n",
    "    \n",
    "    return trainy[np.argmin(a,axis=1)]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([170, 187, 182, 243,  27, 187,  11, 209, 235,  23, 229,  35, 235,\n",
       "        18,  14,   1,  17, 228,  14,  30, 116, 136, 105, 125,  55, 120,\n",
       "        43,  77, 139, 121,  81,  46,  89,  94,  94,  82, 152,  41,  52,\n",
       "       145, 101, 110, 207, 221, 233, 221, 232, 234, 238, 233, 214,  85,\n",
       "        27, 208, 133, 192, 239, 175, 175, 224,   1, 171])"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=np.array([[np.sum(np.absolute(testx[i,]-trainx[j,])) for j in range(len(trainx))] for i in range(len(testx))])\n",
    "np.argmin(a,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "testy_L1 = NN_L1(trainx, trainy, testx)\n",
    "testy_L2 = NN_L2(trainx, trainy, testx)\n",
    "\n",
    "assert( type( testy_L1).__name__ == 'ndarray' )\n",
    "assert( len(testy_L1) == 62 ) \n",
    "#assert( not all(testy_L1 == testy_L2) )\n",
    "assert( all(testy_L1[50:60]== [ 0.,  2.,  1.,  0.,  2.,  0.,  0.,  0.,  0.,  0.]) )\n",
    "assert( all( testy_L1[0:10] == [ 0.,  0.,  0.,  0.,  1.,  0.,  1.,  0.,  0.,  1.]) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 4. Test errors and the confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if the L1 and L2 distance functions yield different error rates for nearest neighbor classification of the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error rate of NN_L1:  0.22580645161290322\n",
      "Error rate of NN_L2:  0.22580645161290322\n"
     ]
    }
   ],
   "source": [
    "def error_rate(testy, testy_fit):\n",
    "    return float(sum(testy!=testy_fit))/len(testy) \n",
    "\n",
    "print(\"Error rate of NN_L1: \", error_rate(testy,testy_L1) )\n",
    "print(\"Error rate of NN_L2: \", error_rate(testy,testy_L2) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now look a bit more deeply into the specific types of errors made by nearest neighbor classification, by constructing the <font color=\"magenta\">*confusion matrix*</font>.\n",
    "\n",
    "Since there are three labels, the confusion matrix is a 3x3 matrix whose rows correspond to the true label and whose columns correspond to the predicted label. For example, the entry at row DH, column SL, contains the number of test points whose correct label was DH but which were classified as SL.\n",
    "\n",
    "<img style=\"width:200px\" src=\"confusion_matrix.png\">\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function, **confusion**, takes as input the true labels for the test set (that is, `testy`) as well as the predicted labels and returns the confusion matrix. The confusion matrix should be a `np.array` of shape `(3,3)` . "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font  style=\"color:blue\"> **Code**</font>\n",
    "```python\n",
    "L2_neo = confusion(testy, testy_L2)  \n",
    "print( type(L2_neo) )\n",
    "print( L2_neo.shape )\n",
    "print( L2_neo )\n",
    "```\n",
    "\n",
    "<font  style=\"color:magenta\"> **Output**</font>\n",
    "```\n",
    "<class 'numpy.ndarray'>\n",
    "(3, 3)\n",
    "[[ 17.   1.   2.]\n",
    " [ 10.  10.   0.]\n",
    " [  0.   0.  22.]]\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify this cell\n",
    "\n",
    "def confusion(testy,testy_fit):\n",
    "    # inputs: the correct labels, the fitted NN labels \n",
    "    # output: a 3x3 np.array representing the confusion matrix as above\n",
    "    return np.array([[np.count_nonzero(testy_fit[testy==j]==i) for i in np.unique(testy)] for j in np.unique(testy)])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[26, 12, 24], [26, 12, 24], [26, 12, 24]]"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "([[np.count_nonzero(testy_L1==i) for i in np.unique(testy)] for j in np.unique(testy)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[17,  1,  2],\n",
       "       [10, 10,  0],\n",
       "       [ 0,  0, 22]])"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion(testy, testy_L2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[16,  2,  2],\n",
       "       [10, 10,  0],\n",
       "       [ 0,  0, 22]])"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion(testy, testy_L1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True, False,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True, False,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True, False,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True, False, False,  True,\n",
       "        True,  True, False,  True,  True,  True, False,  True])"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testy_L1==testy_L2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Function\n",
    "\n",
    "L1_neo = confusion(testy, testy_L1) \n",
    "assert( type(L1_neo).__name__ == 'ndarray' )\n",
    "assert( L1_neo.shape == (3,3) )\n",
    "assert( np.all(L1_neo == [[ 16.,  2.,  2.],[ 10.,  10.,  0.],[ 0.,  0.,  22.]]) )\n",
    "L2_neo = confusion(testy, testy_L2)  \n",
    "assert( np.all(L2_neo == [[ 17.,  1.,  2.],[ 10.,  10.,  0.],[ 0.,  0.,  22.]]) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Some insights \n",
    "\n",
    "\n",
    "* In the test set, which class (NO, DH, or SL) was **most frequently** misclassified by the L1-based nearest neighbor classifier?\n",
    " - DH\n",
    "* In the test set, which class (NO, DH, or SL) was **never** misclassified by the L2-based nearest neighbor classifier?\n",
    " - SL\n",
    "* On **how many** of the test points did the two classification schemes (based on L1 and L2 distance) yield *different* predictions?\n",
    " - 7\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "102px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": false,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_position": {
    "height": "670px",
    "left": "0px",
    "right": "1145px",
    "top": "106px",
    "width": "212px"
   },
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
